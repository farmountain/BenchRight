{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 14 ‚Äî Data Analytics & SQL Evaluation\n",
        "### BenchRight LLM Evaluation Master Program (18 Weeks)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "1. Understand how to evaluate LLM SQL generation capabilities\n",
        "2. Create an in-memory SQLite database for testing\n",
        "3. Implement a two-metric evaluation: execution success and result correctness\n",
        "4. Analyze which types of queries are hardest for models to generate\n",
        "5. Build a complete text-to-SQL evaluation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üß† Why SQL Evaluation is Different\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "Unlike natural language tasks, SQL has **objective correctness criteria**:\n",
        "\n",
        "| Aspect | Natural Language | SQL |\n",
        "|--------|------------------|-----|\n",
        "| Correctness | Multiple phrasings OK | Must execute AND return correct results |\n",
        "| Evaluation | Human judgment needed | Automated testing possible |\n",
        "| Errors | Graceful degradation | Syntax error = complete failure |\n",
        "\n",
        "### What We Evaluate\n",
        "\n",
        "1. **Execution Success:** Does the query run without errors?\n",
        "2. **Result Correctness:** Does the query return the expected answer?\n",
        "3. **Schema Understanding:** Does the model correctly reference tables and columns?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üõ†Ô∏è Step 1: Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import sqlite3\n",
        "import sys\n",
        "import json\n",
        "from typing import Dict, List, Any, Tuple, Optional, Callable\n",
        "\n",
        "# Add src to path if running in Colab\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# For data display\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "except ImportError:\n",
        "    display = print\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"   SQLite version: {sqlite3.sqlite_version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üóÑÔ∏è Step 2: Create the In-Memory SQLite Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sales analytics database schema\n",
        "SCHEMA_SQL = \"\"\"\n",
        "CREATE TABLE customers (\n",
        "    customer_id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    email TEXT,\n",
        "    city TEXT,\n",
        "    signup_date DATE\n",
        ");\n",
        "\n",
        "CREATE TABLE products (\n",
        "    product_id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    category TEXT,\n",
        "    price REAL\n",
        ");\n",
        "\n",
        "CREATE TABLE orders (\n",
        "    order_id INTEGER PRIMARY KEY,\n",
        "    customer_id INTEGER,\n",
        "    order_date DATE,\n",
        "    total_amount REAL,\n",
        "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        ");\n",
        "\n",
        "CREATE TABLE order_items (\n",
        "    item_id INTEGER PRIMARY KEY,\n",
        "    order_id INTEGER,\n",
        "    product_id INTEGER,\n",
        "    quantity INTEGER,\n",
        "    unit_price REAL,\n",
        "    FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Sample data for the database\n",
        "DATA_SQL = \"\"\"\n",
        "INSERT INTO customers VALUES (1, 'Alice Johnson', 'alice@example.com', 'New York', '2023-01-15');\n",
        "INSERT INTO customers VALUES (2, 'Bob Smith', 'bob@example.com', 'Los Angeles', '2023-02-20');\n",
        "INSERT INTO customers VALUES (3, 'Charlie Brown', 'charlie@example.com', 'New York', '2023-03-10');\n",
        "INSERT INTO customers VALUES (4, 'Diana Lee', 'diana@example.com', 'Chicago', '2024-01-05');\n",
        "INSERT INTO customers VALUES (5, 'Eve Wilson', 'eve@example.com', 'Los Angeles', '2024-02-15');\n",
        "\n",
        "INSERT INTO products VALUES (1, 'Laptop', 'Electronics', 999.99);\n",
        "INSERT INTO products VALUES (2, 'Headphones', 'Electronics', 149.99);\n",
        "INSERT INTO products VALUES (3, 'Coffee Maker', 'Appliances', 79.99);\n",
        "INSERT INTO products VALUES (4, 'Desk Chair', 'Furniture', 249.99);\n",
        "INSERT INTO products VALUES (5, 'Monitor', 'Electronics', 399.99);\n",
        "\n",
        "INSERT INTO orders VALUES (1, 1, '2024-01-10', 1149.98);\n",
        "INSERT INTO orders VALUES (2, 1, '2024-02-15', 79.99);\n",
        "INSERT INTO orders VALUES (3, 2, '2024-01-20', 399.99);\n",
        "INSERT INTO orders VALUES (4, 3, '2024-02-01', 249.99);\n",
        "INSERT INTO orders VALUES (5, 4, '2024-03-01', 549.98);\n",
        "INSERT INTO orders VALUES (6, 2, '2024-03-15', 149.99);\n",
        "\n",
        "INSERT INTO order_items VALUES (1, 1, 1, 1, 999.99);\n",
        "INSERT INTO order_items VALUES (2, 1, 2, 1, 149.99);\n",
        "INSERT INTO order_items VALUES (3, 2, 3, 1, 79.99);\n",
        "INSERT INTO order_items VALUES (4, 3, 5, 1, 399.99);\n",
        "INSERT INTO order_items VALUES (5, 4, 4, 1, 249.99);\n",
        "INSERT INTO order_items VALUES (6, 5, 2, 2, 149.99);\n",
        "INSERT INTO order_items VALUES (7, 5, 4, 1, 249.99);\n",
        "INSERT INTO order_items VALUES (8, 6, 2, 1, 149.99);\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìä Database schema and sample data defined!\")\n",
        "print(\"\")\n",
        "print(\"Tables:\")\n",
        "print(\"  ‚Ä¢ customers (5 rows)\")\n",
        "print(\"  ‚Ä¢ products (5 rows)\")\n",
        "print(\"  ‚Ä¢ orders (6 rows)\")\n",
        "print(\"  ‚Ä¢ order_items (8 rows)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üß™ Step 3: Implement the SQLEvaluator Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SQLEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluator for text-to-SQL tasks.\n",
        "    \n",
        "    Uses an in-memory SQLite database to verify:\n",
        "    1. Query execution success\n",
        "    2. Result correctness (compared to reference answer)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, schema_sql: str, data_sql: str):\n",
        "        \"\"\"\n",
        "        Initialize the SQLEvaluator with a database schema and data.\n",
        "        \n",
        "        Args:\n",
        "            schema_sql: SQL statements to create tables\n",
        "            data_sql: SQL statements to insert sample data\n",
        "        \"\"\"\n",
        "        self.schema_sql = schema_sql\n",
        "        self.data_sql = data_sql\n",
        "        self._init_database()\n",
        "    \n",
        "    def _init_database(self) -> None:\n",
        "        \"\"\"Initialize the in-memory SQLite database.\"\"\"\n",
        "        self.conn = sqlite3.connect(':memory:')\n",
        "        self.cursor = self.conn.cursor()\n",
        "        \n",
        "        # Create schema\n",
        "        for statement in self.schema_sql.split(';'):\n",
        "            statement = statement.strip()\n",
        "            if statement:\n",
        "                self.cursor.execute(statement)\n",
        "        \n",
        "        # Insert data\n",
        "        for statement in self.data_sql.split(';'):\n",
        "            statement = statement.strip()\n",
        "            if statement:\n",
        "                self.cursor.execute(statement)\n",
        "        \n",
        "        self.conn.commit()\n",
        "    \n",
        "    def execute_query(self, sql: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute a SQL query and return results.\n",
        "        \n",
        "        Args:\n",
        "            sql: SQL query to execute\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with:\n",
        "            - success: bool indicating if query executed\n",
        "            - result: query results if successful\n",
        "            - columns: column names\n",
        "            - error: error message if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.cursor.execute(sql)\n",
        "            results = self.cursor.fetchall()\n",
        "            columns = [desc[0] for desc in self.cursor.description] if self.cursor.description else []\n",
        "            \n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"result\": results,\n",
        "                \"columns\": columns,\n",
        "                \"error\": None,\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"result\": None,\n",
        "                \"columns\": [],\n",
        "                \"error\": str(e),\n",
        "            }\n",
        "    \n",
        "    def compare_results(\n",
        "        self,\n",
        "        generated_result: List[Tuple],\n",
        "        reference_result: List[Tuple],\n",
        "        order_matters: bool = False,\n",
        "    ) -> bool:\n",
        "        \"\"\"\n",
        "        Compare generated query results with reference results.\n",
        "        \n",
        "        Args:\n",
        "            generated_result: Results from generated query\n",
        "            reference_result: Expected reference results\n",
        "            order_matters: Whether row order should match\n",
        "            \n",
        "        Returns:\n",
        "            True if results match, False otherwise\n",
        "        \"\"\"\n",
        "        if generated_result is None or reference_result is None:\n",
        "            return False\n",
        "        \n",
        "        if order_matters:\n",
        "            return generated_result == reference_result\n",
        "        else:\n",
        "            # Compare as sets of tuples\n",
        "            return set(generated_result) == set(reference_result)\n",
        "    \n",
        "    def evaluate_query(\n",
        "        self,\n",
        "        generated_sql: str,\n",
        "        reference_sql: str,\n",
        "        order_matters: bool = False,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Evaluate a generated SQL query.\n",
        "        \n",
        "        Args:\n",
        "            generated_sql: The SQL query to evaluate\n",
        "            reference_sql: Reference SQL with correct answer\n",
        "            order_matters: Whether result order should match\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with:\n",
        "            - execution_success: bool\n",
        "            - result_match: bool\n",
        "            - generated_result: results from generated query\n",
        "            - reference_result: results from reference query\n",
        "            - error: error message if any\n",
        "        \"\"\"\n",
        "        # Execute reference query to get expected result\n",
        "        ref_execution = self.execute_query(reference_sql)\n",
        "        if not ref_execution[\"success\"]:\n",
        "            return {\n",
        "                \"execution_success\": False,\n",
        "                \"result_match\": False,\n",
        "                \"generated_result\": None,\n",
        "                \"reference_result\": None,\n",
        "                \"error\": f\"Reference query failed: {ref_execution['error']}\",\n",
        "            }\n",
        "        \n",
        "        # Execute generated query\n",
        "        gen_execution = self.execute_query(generated_sql)\n",
        "        \n",
        "        if not gen_execution[\"success\"]:\n",
        "            return {\n",
        "                \"execution_success\": False,\n",
        "                \"result_match\": False,\n",
        "                \"generated_result\": None,\n",
        "                \"reference_result\": ref_execution[\"result\"],\n",
        "                \"error\": gen_execution[\"error\"],\n",
        "            }\n",
        "        \n",
        "        # Compare results\n",
        "        results_match = self.compare_results(\n",
        "            gen_execution[\"result\"],\n",
        "            ref_execution[\"result\"],\n",
        "            order_matters=order_matters,\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"execution_success\": True,\n",
        "            \"result_match\": results_match,\n",
        "            \"generated_result\": gen_execution[\"result\"],\n",
        "            \"reference_result\": ref_execution[\"result\"],\n",
        "            \"error\": None,\n",
        "        }\n",
        "    \n",
        "    def compute_metrics(\n",
        "        self, \n",
        "        results: List[Dict[str, Any]],\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute aggregate metrics across multiple evaluations.\n",
        "        \n",
        "        Args:\n",
        "            results: List of evaluation results\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with:\n",
        "            - execution_rate: proportion of queries that executed\n",
        "            - accuracy: proportion of queries with correct results\n",
        "        \"\"\"\n",
        "        if not results:\n",
        "            return {\"execution_rate\": 0.0, \"accuracy\": 0.0}\n",
        "        \n",
        "        executed = sum(1 for r in results if r[\"execution_success\"])\n",
        "        correct = sum(1 for r in results if r[\"result_match\"])\n",
        "        \n",
        "        return {\n",
        "            \"execution_rate\": executed / len(results),\n",
        "            \"accuracy\": correct / len(results),\n",
        "        }\n",
        "    \n",
        "    def close(self) -> None:\n",
        "        \"\"\"Close the database connection.\"\"\"\n",
        "        self.conn.close()\n",
        "\n",
        "\n",
        "print(\"‚úÖ SQLEvaluator class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üèÉ Step 4: Initialize the Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the SQLEvaluator\n",
        "evaluator = SQLEvaluator(SCHEMA_SQL, DATA_SQL)\n",
        "\n",
        "print(\"‚úÖ SQLEvaluator initialized with in-memory database!\")\n",
        "print(\"\")\n",
        "\n",
        "# Verify database is working\n",
        "test_result = evaluator.execute_query(\"SELECT COUNT(*) FROM customers\")\n",
        "print(f\"Test query result: {test_result['result'][0][0]} customers in database\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìã Step 5: Define Text-to-SQL Test Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive test cases with varying difficulty\n",
        "TEST_CASES = [\n",
        "    # Easy: Simple queries\n",
        "    {\n",
        "        \"name\": \"Simple Count\",\n",
        "        \"question\": \"How many customers are there in total?\",\n",
        "        \"reference_sql\": \"SELECT COUNT(*) FROM customers\",\n",
        "        \"difficulty\": \"easy\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Filter by City\",\n",
        "        \"question\": \"What are the names of customers from New York?\",\n",
        "        \"reference_sql\": \"SELECT name FROM customers WHERE city = 'New York'\",\n",
        "        \"difficulty\": \"easy\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Sum Aggregation\",\n",
        "        \"question\": \"What is the total revenue from all orders?\",\n",
        "        \"reference_sql\": \"SELECT SUM(total_amount) FROM orders\",\n",
        "        \"difficulty\": \"easy\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Average Calculation\",\n",
        "        \"question\": \"What is the average product price?\",\n",
        "        \"reference_sql\": \"SELECT AVG(price) FROM products\",\n",
        "        \"difficulty\": \"easy\",\n",
        "    },\n",
        "    # Medium: Queries with joins or grouping\n",
        "    {\n",
        "        \"name\": \"Group By with Count\",\n",
        "        \"question\": \"How many customers are there in each city?\",\n",
        "        \"reference_sql\": \"SELECT city, COUNT(*) FROM customers GROUP BY city\",\n",
        "        \"difficulty\": \"medium\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Simple Join\",\n",
        "        \"question\": \"List the names of customers who have placed orders.\",\n",
        "        \"reference_sql\": \"SELECT DISTINCT c.name FROM customers c JOIN orders o ON c.customer_id = o.customer_id\",\n",
        "        \"difficulty\": \"medium\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Date Filtering\",\n",
        "        \"question\": \"How many orders were placed in 2024?\",\n",
        "        \"reference_sql\": \"SELECT COUNT(*) FROM orders WHERE order_date >= '2024-01-01'\",\n",
        "        \"difficulty\": \"medium\",\n",
        "    },\n",
        "    # Hard: Complex multi-table queries\n",
        "    {\n",
        "        \"name\": \"Group By with Sum and Join\",\n",
        "        \"question\": \"What is the total sales per product category?\",\n",
        "        \"reference_sql\": \"SELECT p.category, SUM(oi.quantity * oi.unit_price) FROM order_items oi JOIN products p ON oi.product_id = p.product_id GROUP BY p.category\",\n",
        "        \"difficulty\": \"hard\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Subquery\",\n",
        "        \"question\": \"Which customers have placed more than one order?\",\n",
        "        \"reference_sql\": \"SELECT name FROM customers WHERE customer_id IN (SELECT customer_id FROM orders GROUP BY customer_id HAVING COUNT(*) > 1)\",\n",
        "        \"difficulty\": \"hard\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Complex Aggregation with Order\",\n",
        "        \"question\": \"What is the most expensive product in the Electronics category?\",\n",
        "        \"reference_sql\": \"SELECT name, price FROM products WHERE category = 'Electronics' ORDER BY price DESC LIMIT 1\",\n",
        "        \"difficulty\": \"hard\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"üìã Defined {len(TEST_CASES)} test cases:\")\n",
        "print(\"\")\n",
        "for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
        "    cases = [tc for tc in TEST_CASES if tc[\"difficulty\"] == difficulty]\n",
        "    print(f\"  {difficulty.upper()}: {len(cases)} cases\")\n",
        "    for tc in cases:\n",
        "        print(f\"    ‚Ä¢ {tc['name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úì Step 6: Verify Reference Queries Execute Correctly\n",
        "\n",
        "First, let's verify that all our reference SQL queries work as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Verifying Reference Queries...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "verification_results = []\n",
        "for tc in TEST_CASES:\n",
        "    result = evaluator.execute_query(tc[\"reference_sql\"])\n",
        "    \n",
        "    verification_results.append({\n",
        "        \"name\": tc[\"name\"],\n",
        "        \"difficulty\": tc[\"difficulty\"],\n",
        "        \"success\": result[\"success\"],\n",
        "        \"result\": result[\"result\"],\n",
        "        \"error\": result[\"error\"],\n",
        "    })\n",
        "    \n",
        "    status = \"‚úÖ Success\" if result[\"success\"] else \"‚ùå Failed\"\n",
        "    print(f\"\\n{status} [{tc['difficulty']}] {tc['name']}\")\n",
        "    print(f\"   Question: {tc['question']}\")\n",
        "    print(f\"   SQL: {tc['reference_sql']}\")\n",
        "    if result[\"success\"]:\n",
        "        print(f\"   Result: {result['result']}\")\n",
        "    else:\n",
        "        print(f\"   Error: {result['error']}\")\n",
        "\n",
        "# Summary\n",
        "success_count = sum(1 for r in verification_results if r[\"success\"])\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"üìä Reference Query Verification: {success_count}/{len(TEST_CASES)} successful\")\n",
        "if success_count == len(TEST_CASES):\n",
        "    print(\"‚úÖ All reference queries execute successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ü§ñ Step 7: Define Mock Model for Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MockSQLModel:\n",
        "    \"\"\"\n",
        "    Mock model that simulates LLM SQL generation responses.\n",
        "    \n",
        "    For demonstration, it returns correct SQL for some queries\n",
        "    and intentionally incorrect SQL for others to show evaluation.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the mock model.\n",
        "        \n",
        "        Predefine responses for each test case.\n",
        "        Some are correct, some have intentional errors.\n",
        "        \"\"\"\n",
        "        # Map question patterns to SQL responses\n",
        "        # Some correct, some with intentional errors\n",
        "        self.responses = {\n",
        "            # Correct responses\n",
        "            \"How many customers are there in total?\": \n",
        "                \"SELECT COUNT(*) FROM customers\",\n",
        "            \"What are the names of customers from New York?\": \n",
        "                \"SELECT name FROM customers WHERE city = 'New York'\",\n",
        "            \"What is the total revenue from all orders?\": \n",
        "                \"SELECT SUM(total_amount) FROM orders\",\n",
        "            \"What is the average product price?\": \n",
        "                \"SELECT AVG(price) FROM products\",\n",
        "            \"How many customers are there in each city?\": \n",
        "                \"SELECT city, COUNT(*) FROM customers GROUP BY city\",\n",
        "            \"How many orders were placed in 2024?\": \n",
        "                \"SELECT COUNT(*) FROM orders WHERE order_date >= '2024-01-01'\",\n",
        "            \n",
        "            # Intentionally incorrect responses for demonstration\n",
        "            \"List the names of customers who have placed orders.\": \n",
        "                \"SELECT c.name FROM customers c, orders o\",  # Missing join condition - Cartesian product\n",
        "            \"What is the total sales per product category?\": \n",
        "                \"SELECT category, SUM(price) FROM products GROUP BY category\",  # Wrong table/calculation\n",
        "            \"Which customers have placed more than one order?\": \n",
        "                \"SELECT name FROM customers WHERE customer_id IN (SELECT customer_id FROM orders)\",  # Missing HAVING\n",
        "            \"What is the most expensive product in the Electronics category?\": \n",
        "                \"SELECT name FROM products WHERE category = 'Electronics' ORDER BY price\",  # Missing DESC and LIMIT\n",
        "        }\n",
        "    \n",
        "    def generate_sql(self, question: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate SQL for a given question.\n",
        "        \n",
        "        Args:\n",
        "            question: Natural language question\n",
        "            \n",
        "        Returns:\n",
        "            Generated SQL query\n",
        "        \"\"\"\n",
        "        # Look for matching question\n",
        "        for q, sql in self.responses.items():\n",
        "            if question.strip() == q:\n",
        "                return sql\n",
        "        \n",
        "        # Default: return a syntax error query\n",
        "        return \"SELECT * FORM broken_table\"  # Intentional typo\n",
        "\n",
        "\n",
        "# Create mock model\n",
        "mock_model = MockSQLModel()\n",
        "print(\"‚úÖ Mock SQL model created!\")\n",
        "print(\"   (Simulates varying model performance for demonstration)\")\n",
        "print(\"\")\n",
        "print(\"   Correct responses: 6 queries\")\n",
        "print(\"   Incorrect responses: 4 queries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Step 8: Define Text-to-SQL Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Schema description for prompts\n",
        "SCHEMA_DESCRIPTION = \"\"\"\n",
        "Tables:\n",
        "- customers (customer_id, name, email, city, signup_date)\n",
        "- products (product_id, name, category, price)\n",
        "- orders (order_id, customer_id, order_date, total_amount)\n",
        "- order_items (item_id, order_id, product_id, quantity, unit_price)\n",
        "\n",
        "Relationships:\n",
        "- orders.customer_id references customers.customer_id\n",
        "- order_items.order_id references orders.order_id\n",
        "- order_items.product_id references products.product_id\n",
        "\"\"\"\n",
        "\n",
        "TEXT_TO_SQL_PROMPT = \"\"\"You are a SQL expert. Given the following database schema and question, write a SQL query that answers the question.\n",
        "\n",
        "## Database Schema\n",
        "{schema}\n",
        "\n",
        "## Question\n",
        "{question}\n",
        "\n",
        "## Instructions\n",
        "1. Write a valid SQLite query\n",
        "2. Return ONLY the SQL query, no explanations\n",
        "3. Do not include markdown code blocks\n",
        "\n",
        "## SQL Query:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def create_text_to_sql_prompt(question: str) -> str:\n",
        "    \"\"\"Create a prompt for text-to-SQL tasks.\"\"\"\n",
        "    return TEXT_TO_SQL_PROMPT.format(\n",
        "        schema=SCHEMA_DESCRIPTION,\n",
        "        question=question,\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"‚úÖ Prompt template defined!\")\n",
        "print(\"\")\n",
        "print(\"Example prompt:\")\n",
        "print(\"-\" * 40)\n",
        "print(create_text_to_sql_prompt(\"How many customers are there?\")[:300] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üèÉ Step 9: Run the Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Running Text-to-SQL Evaluation...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "evaluation_results = []\n",
        "\n",
        "for tc in TEST_CASES:\n",
        "    # Generate SQL using mock model\n",
        "    generated_sql = mock_model.generate_sql(tc[\"question\"])\n",
        "    \n",
        "    # Evaluate the generated SQL\n",
        "    result = evaluator.evaluate_query(\n",
        "        generated_sql=generated_sql,\n",
        "        reference_sql=tc[\"reference_sql\"],\n",
        "        order_matters=False,\n",
        "    )\n",
        "    \n",
        "    evaluation_results.append({\n",
        "        \"name\": tc[\"name\"],\n",
        "        \"question\": tc[\"question\"],\n",
        "        \"difficulty\": tc[\"difficulty\"],\n",
        "        \"generated_sql\": generated_sql,\n",
        "        \"reference_sql\": tc[\"reference_sql\"],\n",
        "        **result,\n",
        "    })\n",
        "    \n",
        "    # Display results\n",
        "    exec_status = \"‚úÖ\" if result[\"execution_success\"] else \"‚ùå\"\n",
        "    match_status = \"‚úÖ\" if result[\"result_match\"] else \"‚ùå\"\n",
        "    \n",
        "    print(f\"\\n[{tc['difficulty'].upper()}] {tc['name']}\")\n",
        "    print(f\"   Question: {tc['question']}\")\n",
        "    print(f\"   Generated: {generated_sql}\")\n",
        "    print(f\"   Reference: {tc['reference_sql']}\")\n",
        "    print(f\"   Execution: {exec_status} | Result Match: {match_status}\")\n",
        "    if result[\"error\"]:\n",
        "        print(f\"   Error: {result['error']}\")\n",
        "    if result[\"execution_success\"] and not result[\"result_match\"]:\n",
        "        print(f\"   Generated Result: {result['generated_result']}\")\n",
        "        print(f\"   Expected Result: {result['reference_result']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Step 10: Compute and Display Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute overall metrics\n",
        "metrics = evaluator.compute_metrics(evaluation_results)\n",
        "\n",
        "print(\"üìä Overall Evaluation Metrics\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\")\n",
        "print(f\"Total Test Cases: {len(evaluation_results)}\")\n",
        "print(f\"Execution Rate: {metrics['execution_rate']:.0%}\")\n",
        "print(f\"Accuracy (Result Match): {metrics['accuracy']:.0%}\")\n",
        "print(\"\")\n",
        "\n",
        "# Compute metrics by difficulty\n",
        "print(\"üìà Metrics by Difficulty\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
        "    difficulty_results = [r for r in evaluation_results if r[\"difficulty\"] == difficulty]\n",
        "    if difficulty_results:\n",
        "        diff_metrics = evaluator.compute_metrics(difficulty_results)\n",
        "        print(f\"\")\n",
        "        print(f\"{difficulty.upper()} ({len(difficulty_results)} queries):\")\n",
        "        print(f\"   Execution Rate: {diff_metrics['execution_rate']:.0%}\")\n",
        "        print(f\"   Accuracy: {diff_metrics['accuracy']:.0%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìã Step 11: Generate Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìã Evaluation Summary Table\")\n",
        "print(\"=\" * 90)\n",
        "print(f\"{'#':<3} {'Name':<30} {'Difficulty':<10} {'Execution':<12} {'Result Match':<12}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for i, r in enumerate(evaluation_results, 1):\n",
        "    exec_status = \"‚úÖ Pass\" if r[\"execution_success\"] else \"‚ùå Fail\"\n",
        "    match_status = \"‚úÖ Match\" if r[\"result_match\"] else \"‚ùå Mismatch\"\n",
        "    \n",
        "    print(f\"{i:<3} {r['name']:<30} {r['difficulty']:<10} {exec_status:<12} {match_status:<12}\")\n",
        "\n",
        "print(\"-\" * 90)\n",
        "print(f\"\")\n",
        "print(f\"Summary: {metrics['accuracy']:.0%} accuracy across {len(evaluation_results)} test cases\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîç Step 12: Analyze Failure Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze failures\n",
        "execution_failures = [r for r in evaluation_results if not r[\"execution_success\"]]\n",
        "result_mismatches = [r for r in evaluation_results if r[\"execution_success\"] and not r[\"result_match\"]]\n",
        "successes = [r for r in evaluation_results if r[\"result_match\"]]\n",
        "\n",
        "print(\"üîç Failure Analysis\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\")\n",
        "print(f\"‚úÖ Successful: {len(successes)} queries\")\n",
        "print(f\"‚ùå Execution Failures: {len(execution_failures)} queries\")\n",
        "print(f\"‚ö†Ô∏è Result Mismatches: {len(result_mismatches)} queries\")\n",
        "\n",
        "if execution_failures:\n",
        "    print(\"\")\n",
        "    print(\"‚ùå Execution Failures:\")\n",
        "    print(\"-\" * 40)\n",
        "    for r in execution_failures:\n",
        "        print(f\"   ‚Ä¢ {r['name']}: {r['error'][:50]}...\")\n",
        "\n",
        "if result_mismatches:\n",
        "    print(\"\")\n",
        "    print(\"‚ö†Ô∏è Result Mismatches:\")\n",
        "    print(\"-\" * 40)\n",
        "    for r in result_mismatches:\n",
        "        print(f\"   ‚Ä¢ {r['name']}\")\n",
        "        print(f\"     Generated: {r['generated_result']}\")\n",
        "        print(f\"     Expected:  {r['reference_result']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üß™ Step 13: Test with Custom Queries\n",
        "\n",
        "Try your own SQL queries to see the evaluation in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test custom queries\n",
        "print(\"üß™ Custom Query Testing\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Example: Test equivalent queries that return same results\n",
        "custom_tests = [\n",
        "    {\n",
        "        \"name\": \"Equivalent COUNT queries\",\n",
        "        \"generated\": \"SELECT COUNT(customer_id) FROM customers\",\n",
        "        \"reference\": \"SELECT COUNT(*) FROM customers\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Different column alias\",\n",
        "        \"generated\": \"SELECT name AS customer_name FROM customers WHERE city = 'New York'\",\n",
        "        \"reference\": \"SELECT name FROM customers WHERE city = 'New York'\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Wrong filter value\",\n",
        "        \"generated\": \"SELECT name FROM customers WHERE city = 'Boston'\",\n",
        "        \"reference\": \"SELECT name FROM customers WHERE city = 'New York'\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for test in custom_tests:\n",
        "    result = evaluator.evaluate_query(\n",
        "        generated_sql=test[\"generated\"],\n",
        "        reference_sql=test[\"reference\"],\n",
        "    )\n",
        "    \n",
        "    exec_status = \"‚úÖ\" if result[\"execution_success\"] else \"‚ùå\"\n",
        "    match_status = \"‚úÖ\" if result[\"result_match\"] else \"‚ùå\"\n",
        "    \n",
        "    print(f\"\\n{test['name']}\")\n",
        "    print(f\"   Generated: {test['generated']}\")\n",
        "    print(f\"   Reference: {test['reference']}\")\n",
        "    print(f\"   Execution: {exec_status} | Result Match: {match_status}\")\n",
        "    if result[\"execution_success\"]:\n",
        "        print(f\"   Results: {result['generated_result']} vs {result['reference_result']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ Step 14: Query Complexity Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score_query_complexity(sql: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Score the complexity of a SQL query.\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with:\n",
        "        - complexity_score: 1-10 scale\n",
        "        - features: list of detected features\n",
        "        - difficulty: \"easy\", \"medium\", \"hard\"\n",
        "    \"\"\"\n",
        "    sql_upper = sql.upper()\n",
        "    \n",
        "    features = []\n",
        "    score = 1\n",
        "    \n",
        "    # Check for various SQL features\n",
        "    if \"JOIN\" in sql_upper:\n",
        "        features.append(\"JOIN\")\n",
        "        score += 2\n",
        "    \n",
        "    if \"GROUP BY\" in sql_upper:\n",
        "        features.append(\"GROUP BY\")\n",
        "        score += 2\n",
        "    \n",
        "    if \"HAVING\" in sql_upper:\n",
        "        features.append(\"HAVING\")\n",
        "        score += 1\n",
        "    \n",
        "    if sql.upper().count(\"SELECT\") > 1:\n",
        "        features.append(\"SUBQUERY\")\n",
        "        score += 3\n",
        "    \n",
        "    if \"UNION\" in sql_upper:\n",
        "        features.append(\"UNION\")\n",
        "        score += 2\n",
        "    \n",
        "    if \"ORDER BY\" in sql_upper:\n",
        "        features.append(\"ORDER BY\")\n",
        "        score += 1\n",
        "    \n",
        "    if sql.upper().count(\"JOIN\") > 1:\n",
        "        features.append(\"MULTIPLE_JOINS\")\n",
        "        score += 2\n",
        "    \n",
        "    if \"WHERE\" in sql_upper:\n",
        "        features.append(\"WHERE\")\n",
        "        score += 1\n",
        "    \n",
        "    # Determine difficulty\n",
        "    if score <= 2:\n",
        "        difficulty = \"easy\"\n",
        "    elif score <= 5:\n",
        "        difficulty = \"medium\"\n",
        "    else:\n",
        "        difficulty = \"hard\"\n",
        "    \n",
        "    return {\n",
        "        \"complexity_score\": min(score, 10),\n",
        "        \"features\": features,\n",
        "        \"difficulty\": difficulty,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"üéØ Query Complexity Analysis\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for tc in TEST_CASES:\n",
        "    complexity = score_query_complexity(tc[\"reference_sql\"])\n",
        "    print(f\"\\n{tc['name']}\")\n",
        "    print(f\"   SQL: {tc['reference_sql'][:50]}...\" if len(tc['reference_sql']) > 50 else f\"   SQL: {tc['reference_sql']}\")\n",
        "    print(f\"   Score: {complexity['complexity_score']}/10 ({complexity['difficulty']})\")\n",
        "    print(f\"   Features: {', '.join(complexity['features']) if complexity['features'] else 'Basic SELECT'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üßπ Step 15: Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close the database connection\n",
        "evaluator.close()\n",
        "\n",
        "print(\"‚úÖ Database connection closed.\")\n",
        "print(\"\")\n",
        "print(\"üéâ Week 14 Lab Complete!\")\n",
        "print(\"\")\n",
        "print(\"Key Takeaways:\")\n",
        "print(\"  1. SQL evaluation uses two metrics: execution success + result correctness\")\n",
        "print(\"  2. In-memory SQLite provides fast, isolated testing\")\n",
        "print(\"  3. Different query types have varying difficulty levels\")\n",
        "print(\"  4. Result comparison can be order-sensitive or order-insensitive\")\n",
        "print(\"  5. Query complexity scoring helps categorize test cases\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìö Summary\n",
        "\n",
        "In this notebook, you learned how to:\n",
        "\n",
        "1. **Create an in-memory SQLite database** for testing SQL generation\n",
        "2. **Implement the SQLEvaluator class** with execution and result comparison\n",
        "3. **Define test cases** with varying difficulty levels\n",
        "4. **Run evaluations** on generated SQL queries\n",
        "5. **Compute metrics** including execution rate and accuracy\n",
        "6. **Analyze failures** to understand model weaknesses\n",
        "7. **Score query complexity** to categorize evaluation difficulty\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Extend the database schema** with more complex relationships\n",
        "2. **Add more test cases** covering edge cases and advanced SQL features\n",
        "3. **Integrate with a real LLM** instead of the mock model\n",
        "4. **Implement semantic equivalence** for more flexible result comparison\n",
        "5. **Add query performance metrics** (execution time, resource usage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úî Knowledge Mastery Checklist\n",
        "\n",
        "Before moving to Week 15, ensure you can check all boxes:\n",
        "\n",
        "- [ ] I understand why SQL evaluation requires both execution testing and result comparison\n",
        "- [ ] I can create an in-memory SQLite database for testing SQL generation\n",
        "- [ ] I can use the SQLEvaluator to test generated queries\n",
        "- [ ] I understand the two-metric approach: execution success and result correctness\n",
        "- [ ] I can design test cases with varying difficulty levels\n",
        "- [ ] I know how to handle result comparison (order-sensitive vs. order-insensitive)\n",
        "- [ ] I can analyze failure patterns in SQL generation\n",
        "- [ ] I understand query complexity scoring\n",
        "\n",
        "---\n",
        "\n",
        "**Week 14 Complete!**\n",
        "\n",
        "*Next: Week 15 ‚Äî RAG (Retrieval-Augmented Generation) Use Cases*"
      ]
    }
  ]
}
